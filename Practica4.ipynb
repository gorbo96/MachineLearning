{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "9Cm48DGff7tT"
      },
      "source": [
        "# Practica 4 Redes Neuronales\n",
        "## Descripción del problema y dataset\n",
        "Este trabajo contiene datos para la estimación de los niveles de obesidad en personas de los países de México, Perú y Colombia, con edades entre 14 y 61 años y diversos hábitos alimentarios y condición física como lo menciona , los datos se recolectaron utilizando una plataforma web con una encuesta (ver Tabla 1) donde usuarios anónimos respondieron cada pregunta, luego se procesó la información obteniendo 17 atributos y 2111 registros Los atributos relacionados con los hábitos alimentarios son: Consumo frecuente de alimentos altos en calorías (FANG), Frecuencia de consumo de verduras (FCVC), Número de comidas principales (NCP), Consumo de alimentos entre comidas (CAEC), Consumo de agua diario (CH2O) y Consumo de alcohol (CALC). Los atributos relacionados con la condición física son: Monitoreo del consumo de calorías (SCC), Frecuencia de actividad física (PAP), Tiempo usando dispositivos tecnológicos (TUE), Transporte usado (MTRANS), otras variables obtenidas fueron: Sexo, Edad, Altura y Peso. Finalmente, se etiquetaron todos los datos y se creó la variable de clase NObesidad con los valores de Peso Insuficiente, Peso Normal, Sobrepeso Nivel I, Sobrepeso Nivel II, Obesidad Tipo I, Obesidad Tipo II y Obesidad Tipo III, con base en la Ecuación y información de la OMS y Normatividad mexicana.\n",
        "## Preparación de datos (limpieza y preprocesamiento)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUfuy1JY0kaE"
      },
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.model_selection import cross_val_score\n",
        "from sklearn.model_selection import KFold\n",
        "from sklearn.pipeline import Pipeline\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "from tensorflow.python.keras.models import Sequential\n",
        "from tensorflow.python.keras.layers import Dense\n",
        "from tensorflow.python.keras.wrappers.scikit_learn import KerasRegressor\n",
        "from sklearn.preprocessing import OneHotEncoder, StandardScaler\n",
        "from sklearn.compose import make_column_transformer, ColumnTransformer\n",
        "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
        "from sklearn.model_selection import GridSearchCV\n",
        "from keras.layers import Dropout\n",
        "from tensorflow.python.keras.utils import data_utils"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zHaSQACNMV37",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 439
        },
        "outputId": "fcf7c9ac-dc8f-491d-df44-d5630a34e47c"
      },
      "source": [
        "url='https://raw.githubusercontent.com/gorbo96/RedNeuronal1/main/ObesityDataSet_raw_and_data_sinthetic.csv'\n",
        "datos=pd.read_csv(url,sep=\",\")\n",
        "datos"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Gender</th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>family_history_with_overweight</th>\n",
              "      <th>FAVC</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CAEC</th>\n",
              "      <th>SMOKE</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>SCC</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "      <th>CALC</th>\n",
              "      <th>MTRANS</th>\n",
              "      <th>NObeyesdad</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1.620000</td>\n",
              "      <td>64.000000</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>no</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>no</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.000000</td>\n",
              "      <td>1.520000</td>\n",
              "      <td>56.000000</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Male</td>\n",
              "      <td>23.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>77.000000</td>\n",
              "      <td>yes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>no</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Normal_Weight</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>Male</td>\n",
              "      <td>27.000000</td>\n",
              "      <td>1.800000</td>\n",
              "      <td>87.000000</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>no</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Frequently</td>\n",
              "      <td>Walking</td>\n",
              "      <td>Overweight_Level_I</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Male</td>\n",
              "      <td>22.000000</td>\n",
              "      <td>1.780000</td>\n",
              "      <td>89.800000</td>\n",
              "      <td>no</td>\n",
              "      <td>no</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>no</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Overweight_Level_II</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2106</th>\n",
              "      <td>Female</td>\n",
              "      <td>20.976842</td>\n",
              "      <td>1.710730</td>\n",
              "      <td>131.408528</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>1.728139</td>\n",
              "      <td>no</td>\n",
              "      <td>1.676269</td>\n",
              "      <td>0.906247</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Obesity_Type_III</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2107</th>\n",
              "      <td>Female</td>\n",
              "      <td>21.982942</td>\n",
              "      <td>1.748584</td>\n",
              "      <td>133.742943</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.005130</td>\n",
              "      <td>no</td>\n",
              "      <td>1.341390</td>\n",
              "      <td>0.599270</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Obesity_Type_III</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2108</th>\n",
              "      <td>Female</td>\n",
              "      <td>22.524036</td>\n",
              "      <td>1.752206</td>\n",
              "      <td>133.689352</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.054193</td>\n",
              "      <td>no</td>\n",
              "      <td>1.414209</td>\n",
              "      <td>0.646288</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Obesity_Type_III</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2109</th>\n",
              "      <td>Female</td>\n",
              "      <td>24.361936</td>\n",
              "      <td>1.739450</td>\n",
              "      <td>133.346641</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.852339</td>\n",
              "      <td>no</td>\n",
              "      <td>1.139107</td>\n",
              "      <td>0.586035</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Obesity_Type_III</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2110</th>\n",
              "      <td>Female</td>\n",
              "      <td>23.664709</td>\n",
              "      <td>1.738836</td>\n",
              "      <td>133.472641</td>\n",
              "      <td>yes</td>\n",
              "      <td>yes</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>no</td>\n",
              "      <td>2.863513</td>\n",
              "      <td>no</td>\n",
              "      <td>1.026452</td>\n",
              "      <td>0.714137</td>\n",
              "      <td>Sometimes</td>\n",
              "      <td>Public_Transportation</td>\n",
              "      <td>Obesity_Type_III</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>2111 rows × 17 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "      Gender        Age  ...                 MTRANS           NObeyesdad\n",
              "0     Female  21.000000  ...  Public_Transportation        Normal_Weight\n",
              "1     Female  21.000000  ...  Public_Transportation        Normal_Weight\n",
              "2       Male  23.000000  ...  Public_Transportation        Normal_Weight\n",
              "3       Male  27.000000  ...                Walking   Overweight_Level_I\n",
              "4       Male  22.000000  ...  Public_Transportation  Overweight_Level_II\n",
              "...      ...        ...  ...                    ...                  ...\n",
              "2106  Female  20.976842  ...  Public_Transportation     Obesity_Type_III\n",
              "2107  Female  21.982942  ...  Public_Transportation     Obesity_Type_III\n",
              "2108  Female  22.524036  ...  Public_Transportation     Obesity_Type_III\n",
              "2109  Female  24.361936  ...  Public_Transportation     Obesity_Type_III\n",
              "2110  Female  23.664709  ...  Public_Transportation     Obesity_Type_III\n",
              "\n",
              "[2111 rows x 17 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 224
        },
        "id": "yTUVXkCWSLU_",
        "outputId": "d40803f4-5273-413d-c8fa-4be8efbd6e8c"
      },
      "source": [
        "categorico=['Gender','family_history_with_overweight','FAVC','CAEC','SMOKE','CALC','MTRANS']\n",
        "numerico=['Age','Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
        "auxiliar=['Age','Height','Weight','FCVC','NCP','CH2O','FAF','TUE']\n",
        "preprocesador = make_column_transformer(    \n",
        "    ('passthrough',numerico),(OneHotEncoder(),categorico),('drop',['NObeyesdad'])\n",
        "    )\n",
        "DataSet=preprocesador.fit_transform(datos)\n",
        "nombres = preprocesador.transformers_[1][1].get_feature_names(categorico)\n",
        "auxiliar.extend(nombres)\n",
        "DatasetPreprocesado = pd.DataFrame(data=DataSet,columns=auxiliar)\n",
        "DatasetPreprocesado.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Age</th>\n",
              "      <th>Height</th>\n",
              "      <th>Weight</th>\n",
              "      <th>FCVC</th>\n",
              "      <th>NCP</th>\n",
              "      <th>CH2O</th>\n",
              "      <th>FAF</th>\n",
              "      <th>TUE</th>\n",
              "      <th>Gender_Female</th>\n",
              "      <th>Gender_Male</th>\n",
              "      <th>family_history_with_overweight_no</th>\n",
              "      <th>family_history_with_overweight_yes</th>\n",
              "      <th>FAVC_no</th>\n",
              "      <th>FAVC_yes</th>\n",
              "      <th>CAEC_Always</th>\n",
              "      <th>CAEC_Frequently</th>\n",
              "      <th>CAEC_Sometimes</th>\n",
              "      <th>CAEC_no</th>\n",
              "      <th>SMOKE_no</th>\n",
              "      <th>SMOKE_yes</th>\n",
              "      <th>CALC_Always</th>\n",
              "      <th>CALC_Frequently</th>\n",
              "      <th>CALC_Sometimes</th>\n",
              "      <th>CALC_no</th>\n",
              "      <th>MTRANS_Automobile</th>\n",
              "      <th>MTRANS_Bike</th>\n",
              "      <th>MTRANS_Motorbike</th>\n",
              "      <th>MTRANS_Public_Transportation</th>\n",
              "      <th>MTRANS_Walking</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>21.0</td>\n",
              "      <td>1.62</td>\n",
              "      <td>64.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>21.0</td>\n",
              "      <td>1.52</td>\n",
              "      <td>56.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>23.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>77.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>27.0</td>\n",
              "      <td>1.80</td>\n",
              "      <td>87.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>3.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>22.0</td>\n",
              "      <td>1.78</td>\n",
              "      <td>89.8</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    Age  Height  ...  MTRANS_Public_Transportation  MTRANS_Walking\n",
              "0  21.0    1.62  ...                           1.0             0.0\n",
              "1  21.0    1.52  ...                           1.0             0.0\n",
              "2  23.0    1.80  ...                           1.0             0.0\n",
              "3  27.0    1.80  ...                           0.0             1.0\n",
              "4  22.0    1.78  ...                           1.0             0.0\n",
              "\n",
              "[5 rows x 29 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W8KpdtOWT0ZD"
      },
      "source": [
        "DatasetPreprocesado.to_csv(\"final.csv\",sep=\",\");"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wU-tL8j_UH_7",
        "outputId": "852f59de-3ec3-40f3-b779-616c6e3980a4"
      },
      "source": [
        "DatasetPreprocesado.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2111, 29)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 5
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "4x_C1PF7gXsy"
      },
      "source": [
        "## DISEÑO DE RED NEURONAL DE PRUEBA Y EVALUACION\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QSOo7TLyTWJN",
        "outputId": "97123c7c-2f78-468a-8398-3b87e265e8fd"
      },
      "source": [
        "dataset=np.loadtxt(\"final.csv\", delimiter=\",\",skiprows=1)\n",
        "x=dataset[:,1:29]\n",
        "np.delete(x, 3, axis=0)\n",
        "y=dataset[:,3]\n",
        "\n",
        "y=np.reshape(y, (-1,1))\n",
        "\n",
        "#Normalización\n",
        "scaler_x = MinMaxScaler()\n",
        "scaler_y = MinMaxScaler()\n",
        "print(scaler_x.fit(x))\n",
        "xscale=scaler_x.transform(x)\n",
        "print(scaler_y.fit(y))\n",
        "yscale=scaler_y.transform(y)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n",
            "MinMaxScaler(copy=True, feature_range=(0, 1))\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0NFDpQurgLk4"
      },
      "source": [
        "## DIVISION EN TRAIN Y TEST"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "KeKtPUPQWCYC"
      },
      "source": [
        "X_train, X_test, y_train, y_test = train_test_split(xscale, yscale)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aJ1DEG5yWHV6",
        "outputId": "f98bc586-607a-4fc7-ae79-081ffd24beea"
      },
      "source": [
        "model = Sequential()\n",
        "model.add(Dense(12, input_dim=28, kernel_initializer='normal', activation='relu'))\n",
        "model.add(Dense(8, activation='relu'))\n",
        "model.add(Dense(1, activation='sigmoid'))\n",
        "model.summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            "Layer (type)                 Output Shape              Param #   \n",
            "=================================================================\n",
            "dense (Dense)                (None, 12)                348       \n",
            "_________________________________________________________________\n",
            "dense_1 (Dense)              (None, 8)                 104       \n",
            "_________________________________________________________________\n",
            "dense_2 (Dense)              (None, 1)                 9         \n",
            "=================================================================\n",
            "Total params: 461\n",
            "Trainable params: 461\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qfdGrMI_WPYy"
      },
      "source": [
        "model.compile(loss='mse', optimizer='adam', metrics=['mse','mae'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "khO43-T2WQmK",
        "outputId": "f120e482-322b-45b1-e7b9-4829ba6d0bac"
      },
      "source": [
        "history = model.fit(X_train, y_train, epochs=150, batch_size=50,  verbose=1, validation_split=0.2)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/150\n",
            "26/26 [==============================] - 0s 7ms/step - loss: 0.0523 - mse: 0.0523 - mae: 0.1899 - val_loss: 0.0445 - val_mse: 0.0445 - val_mae: 0.1821\n",
            "Epoch 2/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0402 - mse: 0.0402 - mae: 0.1696 - val_loss: 0.0361 - val_mse: 0.0361 - val_mae: 0.1613\n",
            "Epoch 3/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0356 - mse: 0.0356 - mae: 0.1579 - val_loss: 0.0326 - val_mse: 0.0326 - val_mae: 0.1526\n",
            "Epoch 4/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0318 - mse: 0.0318 - mae: 0.1498 - val_loss: 0.0290 - val_mse: 0.0290 - val_mae: 0.1437\n",
            "Epoch 5/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0277 - mse: 0.0277 - mae: 0.1402 - val_loss: 0.0249 - val_mse: 0.0249 - val_mae: 0.1324\n",
            "Epoch 6/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0234 - mse: 0.0234 - mae: 0.1285 - val_loss: 0.0202 - val_mse: 0.0202 - val_mae: 0.1181\n",
            "Epoch 7/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0181 - mse: 0.0181 - mae: 0.1110 - val_loss: 0.0162 - val_mse: 0.0162 - val_mae: 0.1026\n",
            "Epoch 8/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0143 - mse: 0.0143 - mae: 0.0964 - val_loss: 0.0131 - val_mse: 0.0131 - val_mae: 0.0929\n",
            "Epoch 9/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0116 - mse: 0.0116 - mae: 0.0852 - val_loss: 0.0111 - val_mse: 0.0111 - val_mae: 0.0849\n",
            "Epoch 10/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0096 - mse: 0.0096 - mae: 0.0769 - val_loss: 0.0094 - val_mse: 0.0094 - val_mae: 0.0767\n",
            "Epoch 11/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0079 - mse: 0.0079 - mae: 0.0690 - val_loss: 0.0079 - val_mse: 0.0079 - val_mae: 0.0699\n",
            "Epoch 12/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0065 - mse: 0.0065 - mae: 0.0625 - val_loss: 0.0070 - val_mse: 0.0070 - val_mae: 0.0676\n",
            "Epoch 13/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0055 - mse: 0.0055 - mae: 0.0572 - val_loss: 0.0057 - val_mse: 0.0057 - val_mae: 0.0589\n",
            "Epoch 14/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0045 - mse: 0.0045 - mae: 0.0512 - val_loss: 0.0050 - val_mse: 0.0050 - val_mae: 0.0545\n",
            "Epoch 15/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0038 - mse: 0.0038 - mae: 0.0461 - val_loss: 0.0044 - val_mse: 0.0044 - val_mae: 0.0499\n",
            "Epoch 16/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0033 - mse: 0.0033 - mae: 0.0429 - val_loss: 0.0039 - val_mse: 0.0039 - val_mae: 0.0475\n",
            "Epoch 17/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0029 - mse: 0.0029 - mae: 0.0389 - val_loss: 0.0036 - val_mse: 0.0036 - val_mae: 0.0453\n",
            "Epoch 18/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0026 - mse: 0.0026 - mae: 0.0365 - val_loss: 0.0032 - val_mse: 0.0032 - val_mae: 0.0412\n",
            "Epoch 19/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0024 - mse: 0.0024 - mae: 0.0348 - val_loss: 0.0029 - val_mse: 0.0029 - val_mae: 0.0396\n",
            "Epoch 20/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0021 - mse: 0.0021 - mae: 0.0328 - val_loss: 0.0026 - val_mse: 0.0026 - val_mae: 0.0358\n",
            "Epoch 21/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0019 - mse: 0.0019 - mae: 0.0308 - val_loss: 0.0023 - val_mse: 0.0023 - val_mae: 0.0336\n",
            "Epoch 22/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0017 - mse: 0.0017 - mae: 0.0295 - val_loss: 0.0020 - val_mse: 0.0020 - val_mae: 0.0316\n",
            "Epoch 23/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0015 - mse: 0.0015 - mae: 0.0276 - val_loss: 0.0017 - val_mse: 0.0017 - val_mae: 0.0295\n",
            "Epoch 24/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0013 - mse: 0.0013 - mae: 0.0259 - val_loss: 0.0014 - val_mse: 0.0014 - val_mae: 0.0271\n",
            "Epoch 25/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 0.0011 - mse: 0.0011 - mae: 0.0240 - val_loss: 0.0012 - val_mse: 0.0012 - val_mae: 0.0244\n",
            "Epoch 26/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 9.2232e-04 - mse: 9.2232e-04 - mae: 0.0226 - val_loss: 0.0010 - val_mse: 0.0010 - val_mae: 0.0237\n",
            "Epoch 27/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 8.0028e-04 - mse: 8.0028e-04 - mae: 0.0211 - val_loss: 9.2177e-04 - val_mse: 9.2177e-04 - val_mae: 0.0229\n",
            "Epoch 28/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 7.4596e-04 - mse: 7.4596e-04 - mae: 0.0207 - val_loss: 7.9136e-04 - val_mse: 7.9136e-04 - val_mae: 0.0207\n",
            "Epoch 29/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.9798e-04 - mse: 6.9798e-04 - mae: 0.0199 - val_loss: 7.8838e-04 - val_mse: 7.8838e-04 - val_mae: 0.0212\n",
            "Epoch 30/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.4668e-04 - mse: 6.4668e-04 - mae: 0.0192 - val_loss: 6.9874e-04 - val_mse: 6.9874e-04 - val_mae: 0.0196\n",
            "Epoch 31/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 6.0227e-04 - mse: 6.0227e-04 - mae: 0.0187 - val_loss: 6.5038e-04 - val_mse: 6.5038e-04 - val_mae: 0.0190\n",
            "Epoch 32/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.5887e-04 - mse: 5.5887e-04 - mae: 0.0178 - val_loss: 6.1800e-04 - val_mse: 6.1800e-04 - val_mae: 0.0184\n",
            "Epoch 33/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.4581e-04 - mse: 5.4581e-04 - mae: 0.0176 - val_loss: 5.9605e-04 - val_mse: 5.9605e-04 - val_mae: 0.0182\n",
            "Epoch 34/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.1916e-04 - mse: 5.1916e-04 - mae: 0.0171 - val_loss: 5.7731e-04 - val_mse: 5.7731e-04 - val_mae: 0.0179\n",
            "Epoch 35/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 5.0109e-04 - mse: 5.0109e-04 - mae: 0.0169 - val_loss: 5.4600e-04 - val_mse: 5.4600e-04 - val_mae: 0.0171\n",
            "Epoch 36/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.7930e-04 - mse: 4.7930e-04 - mae: 0.0163 - val_loss: 5.1442e-04 - val_mse: 5.1442e-04 - val_mae: 0.0167\n",
            "Epoch 37/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.6348e-04 - mse: 4.6348e-04 - mae: 0.0160 - val_loss: 5.1446e-04 - val_mse: 5.1446e-04 - val_mae: 0.0169\n",
            "Epoch 38/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4715e-04 - mse: 4.4715e-04 - mae: 0.0157 - val_loss: 5.1536e-04 - val_mse: 5.1536e-04 - val_mae: 0.0169\n",
            "Epoch 39/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.4330e-04 - mse: 4.4330e-04 - mae: 0.0158 - val_loss: 4.8577e-04 - val_mse: 4.8577e-04 - val_mae: 0.0163\n",
            "Epoch 40/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.2552e-04 - mse: 4.2552e-04 - mae: 0.0153 - val_loss: 4.7890e-04 - val_mse: 4.7890e-04 - val_mae: 0.0162\n",
            "Epoch 41/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.2991e-04 - mse: 4.2991e-04 - mae: 0.0155 - val_loss: 5.2043e-04 - val_mse: 5.2043e-04 - val_mae: 0.0177\n",
            "Epoch 42/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.1810e-04 - mse: 4.1810e-04 - mae: 0.0153 - val_loss: 4.5580e-04 - val_mse: 4.5580e-04 - val_mae: 0.0156\n",
            "Epoch 43/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 4.0965e-04 - mse: 4.0965e-04 - mae: 0.0150 - val_loss: 4.5181e-04 - val_mse: 4.5181e-04 - val_mae: 0.0154\n",
            "Epoch 44/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0290e-04 - mse: 4.0290e-04 - mae: 0.0147 - val_loss: 4.4798e-04 - val_mse: 4.4798e-04 - val_mae: 0.0155\n",
            "Epoch 45/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 4.0200e-04 - mse: 4.0200e-04 - mae: 0.0149 - val_loss: 4.5104e-04 - val_mse: 4.5104e-04 - val_mae: 0.0156\n",
            "Epoch 46/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9739e-04 - mse: 3.9739e-04 - mae: 0.0146 - val_loss: 4.3490e-04 - val_mse: 4.3490e-04 - val_mae: 0.0151\n",
            "Epoch 47/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9359e-04 - mse: 3.9359e-04 - mae: 0.0147 - val_loss: 4.6181e-04 - val_mse: 4.6181e-04 - val_mae: 0.0166\n",
            "Epoch 48/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.9253e-04 - mse: 3.9253e-04 - mae: 0.0146 - val_loss: 4.2821e-04 - val_mse: 4.2821e-04 - val_mae: 0.0152\n",
            "Epoch 49/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.7666e-04 - mse: 3.7666e-04 - mae: 0.0144 - val_loss: 4.0530e-04 - val_mse: 4.0530e-04 - val_mae: 0.0147\n",
            "Epoch 50/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.6125e-04 - mse: 3.6125e-04 - mae: 0.0139 - val_loss: 3.9913e-04 - val_mse: 3.9913e-04 - val_mae: 0.0145\n",
            "Epoch 51/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.5678e-04 - mse: 3.5678e-04 - mae: 0.0136 - val_loss: 3.9466e-04 - val_mse: 3.9466e-04 - val_mae: 0.0143\n",
            "Epoch 52/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.5421e-04 - mse: 3.5421e-04 - mae: 0.0135 - val_loss: 3.8635e-04 - val_mse: 3.8635e-04 - val_mae: 0.0141\n",
            "Epoch 53/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.4715e-04 - mse: 3.4715e-04 - mae: 0.0135 - val_loss: 3.9688e-04 - val_mse: 3.9688e-04 - val_mae: 0.0146\n",
            "Epoch 54/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.3901e-04 - mse: 3.3901e-04 - mae: 0.0132 - val_loss: 3.8634e-04 - val_mse: 3.8634e-04 - val_mae: 0.0142\n",
            "Epoch 55/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.4039e-04 - mse: 3.4039e-04 - mae: 0.0133 - val_loss: 3.6780e-04 - val_mse: 3.6780e-04 - val_mae: 0.0137\n",
            "Epoch 56/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.3192e-04 - mse: 3.3192e-04 - mae: 0.0131 - val_loss: 3.7101e-04 - val_mse: 3.7101e-04 - val_mae: 0.0138\n",
            "Epoch 57/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.4698e-04 - mse: 3.4698e-04 - mae: 0.0134 - val_loss: 3.6858e-04 - val_mse: 3.6858e-04 - val_mae: 0.0141\n",
            "Epoch 58/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.1002e-04 - mse: 3.1002e-04 - mae: 0.0123 - val_loss: 3.4997e-04 - val_mse: 3.4997e-04 - val_mae: 0.0132\n",
            "Epoch 59/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.0563e-04 - mse: 3.0563e-04 - mae: 0.0123 - val_loss: 3.3896e-04 - val_mse: 3.3896e-04 - val_mae: 0.0130\n",
            "Epoch 60/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 3.0715e-04 - mse: 3.0715e-04 - mae: 0.0126 - val_loss: 3.2811e-04 - val_mse: 3.2811e-04 - val_mae: 0.0126\n",
            "Epoch 61/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.9847e-04 - mse: 2.9847e-04 - mae: 0.0123 - val_loss: 3.2104e-04 - val_mse: 3.2104e-04 - val_mae: 0.0125\n",
            "Epoch 62/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.8889e-04 - mse: 2.8889e-04 - mae: 0.0120 - val_loss: 3.4108e-04 - val_mse: 3.4108e-04 - val_mae: 0.0134\n",
            "Epoch 63/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.9023e-04 - mse: 2.9023e-04 - mae: 0.0121 - val_loss: 3.4456e-04 - val_mse: 3.4456e-04 - val_mae: 0.0133\n",
            "Epoch 64/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.9377e-04 - mse: 2.9377e-04 - mae: 0.0123 - val_loss: 3.6218e-04 - val_mse: 3.6218e-04 - val_mae: 0.0140\n",
            "Epoch 65/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.8518e-04 - mse: 2.8518e-04 - mae: 0.0122 - val_loss: 3.1048e-04 - val_mse: 3.1048e-04 - val_mae: 0.0125\n",
            "Epoch 66/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.7557e-04 - mse: 2.7557e-04 - mae: 0.0118 - val_loss: 3.1338e-04 - val_mse: 3.1338e-04 - val_mae: 0.0126\n",
            "Epoch 67/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.7279e-04 - mse: 2.7279e-04 - mae: 0.0117 - val_loss: 3.1745e-04 - val_mse: 3.1745e-04 - val_mae: 0.0128\n",
            "Epoch 68/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.6461e-04 - mse: 2.6461e-04 - mae: 0.0115 - val_loss: 2.9289e-04 - val_mse: 2.9289e-04 - val_mae: 0.0120\n",
            "Epoch 69/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.6272e-04 - mse: 2.6272e-04 - mae: 0.0113 - val_loss: 3.1633e-04 - val_mse: 3.1633e-04 - val_mae: 0.0129\n",
            "Epoch 70/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.6754e-04 - mse: 2.6754e-04 - mae: 0.0117 - val_loss: 3.0664e-04 - val_mse: 3.0664e-04 - val_mae: 0.0123\n",
            "Epoch 71/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.6188e-04 - mse: 2.6188e-04 - mae: 0.0114 - val_loss: 3.4197e-04 - val_mse: 3.4197e-04 - val_mae: 0.0142\n",
            "Epoch 72/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.7968e-04 - mse: 2.7968e-04 - mae: 0.0120 - val_loss: 2.9262e-04 - val_mse: 2.9262e-04 - val_mae: 0.0121\n",
            "Epoch 73/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.5382e-04 - mse: 2.5382e-04 - mae: 0.0110 - val_loss: 2.9248e-04 - val_mse: 2.9248e-04 - val_mae: 0.0120\n",
            "Epoch 74/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.5382e-04 - mse: 2.5382e-04 - mae: 0.0111 - val_loss: 2.8320e-04 - val_mse: 2.8320e-04 - val_mae: 0.0117\n",
            "Epoch 75/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.4879e-04 - mse: 2.4879e-04 - mae: 0.0109 - val_loss: 2.8579e-04 - val_mse: 2.8579e-04 - val_mae: 0.0118\n",
            "Epoch 76/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.5631e-04 - mse: 2.5631e-04 - mae: 0.0113 - val_loss: 2.7835e-04 - val_mse: 2.7835e-04 - val_mae: 0.0117\n",
            "Epoch 77/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.5066e-04 - mse: 2.5066e-04 - mae: 0.0111 - val_loss: 2.7265e-04 - val_mse: 2.7265e-04 - val_mae: 0.0112\n",
            "Epoch 78/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.4942e-04 - mse: 2.4942e-04 - mae: 0.0111 - val_loss: 2.7098e-04 - val_mse: 2.7098e-04 - val_mae: 0.0114\n",
            "Epoch 79/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.4238e-04 - mse: 2.4238e-04 - mae: 0.0107 - val_loss: 2.7095e-04 - val_mse: 2.7095e-04 - val_mae: 0.0115\n",
            "Epoch 80/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.4040e-04 - mse: 2.4040e-04 - mae: 0.0107 - val_loss: 2.6829e-04 - val_mse: 2.6829e-04 - val_mae: 0.0113\n",
            "Epoch 81/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.3492e-04 - mse: 2.3492e-04 - mae: 0.0105 - val_loss: 2.6473e-04 - val_mse: 2.6473e-04 - val_mae: 0.0111\n",
            "Epoch 82/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.4104e-04 - mse: 2.4104e-04 - mae: 0.0108 - val_loss: 2.5479e-04 - val_mse: 2.5479e-04 - val_mae: 0.0108\n",
            "Epoch 83/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.4410e-04 - mse: 2.4410e-04 - mae: 0.0109 - val_loss: 2.7187e-04 - val_mse: 2.7187e-04 - val_mae: 0.0118\n",
            "Epoch 84/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.3327e-04 - mse: 2.3327e-04 - mae: 0.0104 - val_loss: 2.6886e-04 - val_mse: 2.6886e-04 - val_mae: 0.0115\n",
            "Epoch 85/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.3196e-04 - mse: 2.3196e-04 - mae: 0.0104 - val_loss: 2.6474e-04 - val_mse: 2.6474e-04 - val_mae: 0.0113\n",
            "Epoch 86/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.3196e-04 - mse: 2.3196e-04 - mae: 0.0106 - val_loss: 2.4895e-04 - val_mse: 2.4895e-04 - val_mae: 0.0106\n",
            "Epoch 87/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.2591e-04 - mse: 2.2591e-04 - mae: 0.0102 - val_loss: 2.7159e-04 - val_mse: 2.7159e-04 - val_mae: 0.0116\n",
            "Epoch 88/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.2423e-04 - mse: 2.2423e-04 - mae: 0.0102 - val_loss: 2.5593e-04 - val_mse: 2.5593e-04 - val_mae: 0.0110\n",
            "Epoch 89/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.2270e-04 - mse: 2.2270e-04 - mae: 0.0102 - val_loss: 2.7509e-04 - val_mse: 2.7509e-04 - val_mae: 0.0118\n",
            "Epoch 90/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.2669e-04 - mse: 2.2669e-04 - mae: 0.0104 - val_loss: 2.4866e-04 - val_mse: 2.4866e-04 - val_mae: 0.0107\n",
            "Epoch 91/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.1941e-04 - mse: 2.1941e-04 - mae: 0.0101 - val_loss: 2.5846e-04 - val_mse: 2.5846e-04 - val_mae: 0.0111\n",
            "Epoch 92/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.2367e-04 - mse: 2.2367e-04 - mae: 0.0104 - val_loss: 2.6569e-04 - val_mse: 2.6569e-04 - val_mae: 0.0114\n",
            "Epoch 93/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.1757e-04 - mse: 2.1757e-04 - mae: 0.0099 - val_loss: 2.6320e-04 - val_mse: 2.6320e-04 - val_mae: 0.0115\n",
            "Epoch 94/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.1296e-04 - mse: 2.1296e-04 - mae: 0.0099 - val_loss: 2.4453e-04 - val_mse: 2.4453e-04 - val_mae: 0.0108\n",
            "Epoch 95/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.1367e-04 - mse: 2.1367e-04 - mae: 0.0101 - val_loss: 2.3138e-04 - val_mse: 2.3138e-04 - val_mae: 0.0101\n",
            "Epoch 96/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.1086e-04 - mse: 2.1086e-04 - mae: 0.0100 - val_loss: 2.3466e-04 - val_mse: 2.3466e-04 - val_mae: 0.0105\n",
            "Epoch 97/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.1066e-04 - mse: 2.1066e-04 - mae: 0.0098 - val_loss: 2.2150e-04 - val_mse: 2.2150e-04 - val_mae: 0.0099\n",
            "Epoch 98/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.0678e-04 - mse: 2.0678e-04 - mae: 0.0098 - val_loss: 2.2176e-04 - val_mse: 2.2176e-04 - val_mae: 0.0099\n",
            "Epoch 99/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.9886e-04 - mse: 1.9886e-04 - mae: 0.0095 - val_loss: 2.3971e-04 - val_mse: 2.3971e-04 - val_mae: 0.0108\n",
            "Epoch 100/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.0201e-04 - mse: 2.0201e-04 - mae: 0.0095 - val_loss: 2.2167e-04 - val_mse: 2.2167e-04 - val_mae: 0.0098\n",
            "Epoch 101/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.0006e-04 - mse: 2.0006e-04 - mae: 0.0096 - val_loss: 2.3084e-04 - val_mse: 2.3084e-04 - val_mae: 0.0103\n",
            "Epoch 102/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.0225e-04 - mse: 2.0225e-04 - mae: 0.0097 - val_loss: 2.2536e-04 - val_mse: 2.2536e-04 - val_mae: 0.0105\n",
            "Epoch 103/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.1336e-04 - mse: 2.1336e-04 - mae: 0.0103 - val_loss: 2.4046e-04 - val_mse: 2.4046e-04 - val_mae: 0.0113\n",
            "Epoch 104/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 2.0330e-04 - mse: 2.0330e-04 - mae: 0.0100 - val_loss: 2.1281e-04 - val_mse: 2.1281e-04 - val_mae: 0.0096\n",
            "Epoch 105/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.9157e-04 - mse: 1.9157e-04 - mae: 0.0093 - val_loss: 2.5390e-04 - val_mse: 2.5390e-04 - val_mae: 0.0118\n",
            "Epoch 106/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 2.1052e-04 - mse: 2.1052e-04 - mae: 0.0104 - val_loss: 2.1416e-04 - val_mse: 2.1416e-04 - val_mae: 0.0103\n",
            "Epoch 107/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.9152e-04 - mse: 1.9152e-04 - mae: 0.0095 - val_loss: 2.3902e-04 - val_mse: 2.3902e-04 - val_mae: 0.0114\n",
            "Epoch 108/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.9678e-04 - mse: 1.9678e-04 - mae: 0.0097 - val_loss: 2.1305e-04 - val_mse: 2.1305e-04 - val_mae: 0.0097\n",
            "Epoch 109/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.8618e-04 - mse: 1.8618e-04 - mae: 0.0092 - val_loss: 2.0138e-04 - val_mse: 2.0138e-04 - val_mae: 0.0095\n",
            "Epoch 110/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7987e-04 - mse: 1.7987e-04 - mae: 0.0088 - val_loss: 2.0031e-04 - val_mse: 2.0031e-04 - val_mae: 0.0095\n",
            "Epoch 111/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.8092e-04 - mse: 1.8092e-04 - mae: 0.0089 - val_loss: 1.9914e-04 - val_mse: 1.9914e-04 - val_mae: 0.0093\n",
            "Epoch 112/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7670e-04 - mse: 1.7670e-04 - mae: 0.0088 - val_loss: 2.0884e-04 - val_mse: 2.0884e-04 - val_mae: 0.0096\n",
            "Epoch 113/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7732e-04 - mse: 1.7732e-04 - mae: 0.0088 - val_loss: 2.1736e-04 - val_mse: 2.1736e-04 - val_mae: 0.0104\n",
            "Epoch 114/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7732e-04 - mse: 1.7732e-04 - mae: 0.0089 - val_loss: 2.5773e-04 - val_mse: 2.5773e-04 - val_mae: 0.0125\n",
            "Epoch 115/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.8891e-04 - mse: 1.8891e-04 - mae: 0.0097 - val_loss: 1.9690e-04 - val_mse: 1.9690e-04 - val_mae: 0.0093\n",
            "Epoch 116/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7658e-04 - mse: 1.7658e-04 - mae: 0.0090 - val_loss: 1.8763e-04 - val_mse: 1.8763e-04 - val_mae: 0.0088\n",
            "Epoch 117/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6927e-04 - mse: 1.6927e-04 - mae: 0.0085 - val_loss: 1.8323e-04 - val_mse: 1.8323e-04 - val_mae: 0.0087\n",
            "Epoch 118/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6777e-04 - mse: 1.6777e-04 - mae: 0.0084 - val_loss: 1.8732e-04 - val_mse: 1.8732e-04 - val_mae: 0.0088\n",
            "Epoch 119/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6698e-04 - mse: 1.6698e-04 - mae: 0.0084 - val_loss: 1.8383e-04 - val_mse: 1.8383e-04 - val_mae: 0.0088\n",
            "Epoch 120/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6373e-04 - mse: 1.6373e-04 - mae: 0.0084 - val_loss: 1.8268e-04 - val_mse: 1.8268e-04 - val_mae: 0.0088\n",
            "Epoch 121/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.6255e-04 - mse: 1.6255e-04 - mae: 0.0084 - val_loss: 1.7779e-04 - val_mse: 1.7779e-04 - val_mae: 0.0084\n",
            "Epoch 122/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.5978e-04 - mse: 1.5978e-04 - mae: 0.0081 - val_loss: 1.7592e-04 - val_mse: 1.7592e-04 - val_mae: 0.0085\n",
            "Epoch 123/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6554e-04 - mse: 1.6554e-04 - mae: 0.0087 - val_loss: 1.7125e-04 - val_mse: 1.7125e-04 - val_mae: 0.0085\n",
            "Epoch 124/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6804e-04 - mse: 1.6804e-04 - mae: 0.0089 - val_loss: 1.7845e-04 - val_mse: 1.7845e-04 - val_mae: 0.0088\n",
            "Epoch 125/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6091e-04 - mse: 1.6091e-04 - mae: 0.0084 - val_loss: 1.9415e-04 - val_mse: 1.9415e-04 - val_mae: 0.0100\n",
            "Epoch 126/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7179e-04 - mse: 1.7179e-04 - mae: 0.0095 - val_loss: 1.6633e-04 - val_mse: 1.6633e-04 - val_mae: 0.0084\n",
            "Epoch 127/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.6255e-04 - mse: 1.6255e-04 - mae: 0.0088 - val_loss: 2.3226e-04 - val_mse: 2.3226e-04 - val_mae: 0.0121\n",
            "Epoch 128/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.7061e-04 - mse: 1.7061e-04 - mae: 0.0093 - val_loss: 1.8080e-04 - val_mse: 1.8080e-04 - val_mae: 0.0097\n",
            "Epoch 129/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.5786e-04 - mse: 1.5786e-04 - mae: 0.0085 - val_loss: 1.6842e-04 - val_mse: 1.6842e-04 - val_mae: 0.0086\n",
            "Epoch 130/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.5072e-04 - mse: 1.5072e-04 - mae: 0.0080 - val_loss: 1.7194e-04 - val_mse: 1.7194e-04 - val_mae: 0.0094\n",
            "Epoch 131/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.5021e-04 - mse: 1.5021e-04 - mae: 0.0082 - val_loss: 1.6263e-04 - val_mse: 1.6263e-04 - val_mae: 0.0086\n",
            "Epoch 132/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.4465e-04 - mse: 1.4465e-04 - mae: 0.0079 - val_loss: 1.6113e-04 - val_mse: 1.6113e-04 - val_mae: 0.0082\n",
            "Epoch 133/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.5037e-04 - mse: 1.5037e-04 - mae: 0.0083 - val_loss: 1.6052e-04 - val_mse: 1.6052e-04 - val_mae: 0.0085\n",
            "Epoch 134/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.4159e-04 - mse: 1.4159e-04 - mae: 0.0076 - val_loss: 1.5327e-04 - val_mse: 1.5327e-04 - val_mae: 0.0078\n",
            "Epoch 135/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.4615e-04 - mse: 1.4615e-04 - mae: 0.0081 - val_loss: 1.6440e-04 - val_mse: 1.6440e-04 - val_mae: 0.0090\n",
            "Epoch 136/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.4551e-04 - mse: 1.4551e-04 - mae: 0.0081 - val_loss: 1.5506e-04 - val_mse: 1.5506e-04 - val_mae: 0.0079\n",
            "Epoch 137/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.5032e-04 - mse: 1.5032e-04 - mae: 0.0084 - val_loss: 1.4553e-04 - val_mse: 1.4553e-04 - val_mae: 0.0076\n",
            "Epoch 138/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.4327e-04 - mse: 1.4327e-04 - mae: 0.0080 - val_loss: 1.4483e-04 - val_mse: 1.4483e-04 - val_mae: 0.0075\n",
            "Epoch 139/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.3406e-04 - mse: 1.3406e-04 - mae: 0.0074 - val_loss: 1.5568e-04 - val_mse: 1.5568e-04 - val_mae: 0.0083\n",
            "Epoch 140/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.3652e-04 - mse: 1.3652e-04 - mae: 0.0077 - val_loss: 1.5539e-04 - val_mse: 1.5539e-04 - val_mae: 0.0082\n",
            "Epoch 141/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.4155e-04 - mse: 1.4155e-04 - mae: 0.0079 - val_loss: 1.4846e-04 - val_mse: 1.4846e-04 - val_mae: 0.0078\n",
            "Epoch 142/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.3650e-04 - mse: 1.3650e-04 - mae: 0.0079 - val_loss: 1.5050e-04 - val_mse: 1.5050e-04 - val_mae: 0.0083\n",
            "Epoch 143/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.3269e-04 - mse: 1.3269e-04 - mae: 0.0076 - val_loss: 1.5587e-04 - val_mse: 1.5587e-04 - val_mae: 0.0088\n",
            "Epoch 144/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.3147e-04 - mse: 1.3147e-04 - mae: 0.0073 - val_loss: 1.4530e-04 - val_mse: 1.4530e-04 - val_mae: 0.0078\n",
            "Epoch 145/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.3016e-04 - mse: 1.3016e-04 - mae: 0.0075 - val_loss: 1.5124e-04 - val_mse: 1.5124e-04 - val_mae: 0.0087\n",
            "Epoch 146/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.2890e-04 - mse: 1.2890e-04 - mae: 0.0073 - val_loss: 1.4206e-04 - val_mse: 1.4206e-04 - val_mae: 0.0081\n",
            "Epoch 147/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.2516e-04 - mse: 1.2516e-04 - mae: 0.0072 - val_loss: 1.3300e-04 - val_mse: 1.3300e-04 - val_mae: 0.0072\n",
            "Epoch 148/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.2317e-04 - mse: 1.2317e-04 - mae: 0.0070 - val_loss: 1.3604e-04 - val_mse: 1.3604e-04 - val_mae: 0.0076\n",
            "Epoch 149/150\n",
            "26/26 [==============================] - 0s 3ms/step - loss: 1.2993e-04 - mse: 1.2993e-04 - mae: 0.0077 - val_loss: 1.3910e-04 - val_mse: 1.3910e-04 - val_mae: 0.0078\n",
            "Epoch 150/150\n",
            "26/26 [==============================] - 0s 2ms/step - loss: 1.2809e-04 - mse: 1.2809e-04 - mae: 0.0074 - val_loss: 1.3335e-04 - val_mse: 1.3335e-04 - val_mae: 0.0073\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 312
        },
        "id": "pUXUGhoVWhyK",
        "outputId": "22327055-294e-4936-95e6-ac25a20d934b"
      },
      "source": [
        "#Visualización de accuracy\n",
        "print(history.history.keys())\n",
        "# \"Loss\"\n",
        "plt.plot(history.history['loss'])\n",
        "plt.plot(history.history['val_loss'])\n",
        "plt.title('model loss')\n",
        "plt.ylabel('loss')\n",
        "plt.xlabel('epoch')\n",
        "plt.legend(['train', 'validation'], loc='upper left')\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "dict_keys(['loss', 'mse', 'mae', 'val_loss', 'val_mse', 'val_mae'])\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "im6Q7_RUgeUH"
      },
      "source": [
        "## PREDICCION - USO DEL MODELO DE PRUEBA "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hZipSAWBWnN6",
        "outputId": "64355fa6-ab1a-41f2-c226-8b5c519261ce"
      },
      "source": [
        "#Predicciones:\n",
        "\n",
        "Xnew = np.array([[21.0,1.62,64.0,2.0,3.0,2.0,0.0,1.0,1.0,0.0,0.0,1.0,1.0,0.0,0.0,0.0,1.0,0.0,1.0,0.0,0.0,0.0,0.0,1.0,0.0,0.0,0.0,1.0]])#nuevo cliente\n",
        "\n",
        "Xnew= scaler_x.transform(Xnew)\n",
        "ynew= model.predict(Xnew)\n",
        "#invert normalize\n",
        "ynew = scaler_y.inverse_transform(ynew) \n",
        "Xnew = scaler_x.inverse_transform(Xnew)\n",
        "print(\"X=%s, Predicted=%s\" % (Xnew[0], ynew[0]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "X=[21.    1.62 64.    2.    3.    2.    0.    1.    1.    0.    0.    1.\n",
            "  1.    0.    0.    0.    1.    0.    1.    0.    0.    0.    0.    1.\n",
            "  0.    0.    0.    1.  ], Predicted=[64.16748]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "kOM-yyMagRxv"
      },
      "source": [
        "## ALMACENAMIENTO Y CARGA DE MODELOS DE REDES NEURONALES"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "R-YTqrkla8Dv"
      },
      "source": [
        "def guardarRNN(model,nombreArchivoModelo,nombreArchivoPesos):\n",
        "    print(\"Guardando Red Neuronal en Archivo\")  \n",
        "    # serializar modelo a JSON\n",
        "\n",
        "    # Guardar los Pesos (weights)\n",
        "    model.save_weights(nombreArchivoPesos+'.h5')\n",
        "\n",
        "    # Guardar la Arquitectura del modelo\n",
        "    with open(nombreArchivoModelo+'.json', 'w') as f:\n",
        "        f.write(model.to_json())\n",
        "\n",
        "    print(\"Red Neuronal Grabada en Archivo\")   \n",
        "    \n",
        "def cargarRNN(nombreArchivoModelo,nombreArchivoPesos):\n",
        "        \n",
        "    # Cargar la Arquitectura desde el archivo JSON\n",
        "    with open(nombreArchivoModelo+'.json', 'r') as f:\n",
        "        model = model_from_json(f.read())\n",
        "\n",
        "    # Cargar Pesos (weights) en el nuevo modelo\n",
        "    model.load_weights(nombreArchivoPesos+'.h5')  \n",
        "\n",
        "    print(\"Red Neuronal Cargada desde Archivo\") \n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}